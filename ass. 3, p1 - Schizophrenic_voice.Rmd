---
title: "ass. 3, p1 - Schizophrenia_voice"
author: "Astrid L."
date: "2/11/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 2 - Part 1 - Assessing voice in schizophrenia

Schizophrenia has been associated with "inappropriate" voice, sometimes monotone, sometimes croaky. A few studies indicate that pitch might be an index of schizophrenia. However, an ongoing meta-analysis of the literature (which you will have a go at in the last assignment) indicates that pitch mean and standard deviation are only weak indicators of diagnosis. Can we do better with our new fancy complex skills?

The corpus you are asked to analyse is a set of voice recordings from people with schizophrenia (just after first diagnosis) and 1-1 matched controls (on gender, age, education). Each participant watched 10 videos of triangles moving across the screen and had to describe them (so you have circa 10 recordings per person). I have already extracted the pitch once every 10 milliseconds and you will have to use this data to assess differences in the voice.

N.B. Question to be answered via email to Celine: can you characterize voice in schizophrenia as acoustically different? Report the methods you used to answer this question and the results from the analyses. Add a couple of lines trying to interpret the results (make sense of the difference). E.g. People with schizophrenia tend to have high-pitched voice, and present bigger swings in their prosody than controls. Add a couple of lines describing limitations of the data/analyses if any is relevant.

N.B. There are looots of files to be dealt with. Probably too many for your computer. This is a challenge for you. Some (complementary) possible strategies: You can select a subset of files only (and you have to justify your choice). You can learn how to use the apply() or map() functions. You can coordinate with classmates.
```{r}
# setting working directory, loading data
getwd()
locpath= getwd()
setwd(locpath)
data_random_pitch = read.table("~/Desktop/Exp. Met. 3/Task_3/Pitch/Study1D0S101T3_f0.txt", header = TRUE)
# read.delim (?)
# all_data_df_test$Subject = gsub("c", "", all_data_df_test$Subject, all_data_df_test$Subject)
# loading libraries
library(pacman)
p_load(plyr, dplyr, stringr, tidyverse, tidyr, ggplot2, pastecs, lmerTest, MuMIn, lme4, modelr, Metrics, caret, ddalpha, ggplot2, pastecs, crqa, lmerTest) # choose n (y/n?) in ddalpha
```

1. In the course of this assignment you have to first select one datafile and figure out how to:

- Extract "standard" descriptors of pitch: Mean, standard deviation, range
- Extract less "standard" descriptors of pitch you can think of (e.g. median, iqr, mean absoluted deviation, coefficient of variation)
- Extract "complex" descriptors: recurrence quantification analysis
```{r}
# 1
# descriptive statistics (using the desc function from pastecs):
desc = stat.desc(data_random_pitch) 

# write down later

# extract "complex" descriptors - recurrence quantification analysis:
par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")
ans = optimizeParam(data_random_pitch, data_random_pitch, par, min.rec = 3.5, max.rec = 4.5)
Results=crqa (data_random_pitch, data_random_pitch, delay=ans$delay, embed = ans$emddim, radius=ans$radius,normalize=0,rescale=0,mindiagline = 2,minvertline = 2)
ans
# Represent the plot:
RP=Results$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP)) 
cols = c("white","blue4")
image(RP, xlab = "", ylab = "", col = cols)
#Explore the lags of coordination:
Profile=drpdfromts(data_random_pitch, data_random_pitch,datatype = 'continuous',ws=50,radius=ans$radius)
timecourse = round( seq(-5000,5000,100)/1000, digit = 1)
maxlag = Profile$maxlag/1000
profile = Profile$profile*100
Prof=data.frame(profile)
ggplot(Prof, aes(timecourse,profile))+geom_line()+ geom_vline(xintercept = timecourse[maxlag], colour='red')

mutual(data_random_pitch$f0,lag.max = 50) # run average mutual information for data_random_pitch$f0
fnn=false.nearest(data_random_pitch$f0,m=10,d=22,t=0) # run false-nearest-neighbor analysis
plot(fnn) # plot results of fnn analysis of f0

# results 
Results

# psych package 
# describe(data)
# Extract 

# nbr.val, nbr.null, nbr.na, min max, range, sum, 
# median, mean, SE.mean, CI.mean, var, std.dev, coef.var

```

crqa
delays
no of dimensions
radius

nutual()
rutjal
rutual

gives the combined outcome
use try() when running the loop, it will make the loop keep running although there is an error, just spit out the error and keep running. 
the function from the slide will choose the most conservative
optimized param always makes an error 
optimize parameters
crqa 

diagnosis
0 = control 
1 = schizophrenia 
S = subject no (study 1 = 101, 102; study 3 = 301, 302, etc.)
trial 1 = first video they describe, trial 2 = second video
studynumber

2. Second you will have to turn the code into a function and loop through all the files (or even better use apply/sapply/lapply)
- Remember to extract the relevant information from the file names (Participant, Diagnosis, Trial, Study)

```{r}

# make loop - f(x) / performance
# outcome variables 
filelist = list.files(path = "~/Desktop/Exp. Met. 3/Task_3/Pitch",pattern="*.txt")
setwd("~/Desktop/Exp. Met. 3/Task_3/Pitch")

Mean_pitch = NULL
SD_pitch = NULL
Participant = NULL
n = 1
Radius = 0

# loop 
For (i in filelist) { 
  x = read.delim(i)
  x = x$f0
    ID = str_extract(i, "S + \\d+")
  Participant[n] = str.extract (ID, "d\\D+")
  Mean_pitch[n] = round(mean(x, ra.rm = T), 2)
  SD_pitch[n] = SD(x, na.rm = T)
  V = optimizeParam(x, x, par, min.rec = 3.5, max.rec = 4.5)
  if (length(V) >1)  { 
     Radius[n] = V$radius
     Delay = V$delay
     Embed = V$emddim
  
  n = n+1

  }}

df = data.frame(Participant, Mean_pitch, SD_pitch)
write.csv(df, file = "Pitchfile.csv")

# LOOP


#___________________
# make a list of the files that we are running through
files <- list.files(path = "~/Desktop/Exp. Met. 3/Task_3/Pitch",pattern="*.txt", recursive = TRUE)
setwd("~/Desktop/Exp. Met. 3/Task_3/Pitch")


# make empty list for all the information of interest
Subject <- NULL
study <-  NULL
trial <-  NULL
diagnosis <-  NULL
PR = NULL
DET <- NULL
NRLINE <- NULL
maxL <- NULL
L <- NULL
ENTR <- NULL
LAM <- NULL
TT <- NULL
mean <- NULL
sd <- NULL
range <- NULL
median <- NULL
IQR = NULL
mad = NULL
coef_var = NULL

# for every loop n will be increased by 1 so that we can distinguish between each file
n = 1

# for loop to run through each file in the list (files) we have already created above
for (file in files) {
  
  # read the file into a data frame to be used in the loop
  df = read.delim(file)
  
  # on trying basis:
  Study = str_extract(file, "Study+\\d")
  study[n] = str_extract(Study, "\\d")
  ID = str_extract(file, "S+\\d+")
  Subject[n] = str_extract(ID, "\\d+")
  Diagnosis = str_extract(file, "D+\\d")
  diagnosis[n] = str_extract(Diagnosis, "\\d")
  Trial = str_extract(file, "T+\\d+")
  trial[n] = str_extract(Trial, "\\d+")

  # create the values to be put in each of the empty lists that we created above
  mean[n] <- mean(df$f0)
  sd[n] <- sd(df$f0)
  range[n] <- range(df$f0)
  median[n] <- median(df$f0)
  IQR[n] <- IQR(df$f0)
  mad[n] <- mad(df$f0,center = mean(df$f0))
  coef_var[n] <- sd(df$f0)/mean(df$f0)*100
  
  # set parameterlist and optimize them
  par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")
  
  parameters <- try(optimizeParam(df$f0, df$f0, par, min.rec = 3.5, max.rec = 4.5))
  
  # this if/else statement assures that we the files that does not fit the parameters are still considered in the final lists 
  if (length(parameters) > 1) {
  
  results1 <- crqa(df$f0, df$f0, delay = parameters$delay, embed = parameters$emddim, radius = parameters$radius, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2)
  
  PR[n] = results1$RR
  DET[n] <- results1$DET
  NRLINE[n] <- results1$NRLINE
  maxL[n] <- results1$maxL
  L[n] <- results1$L
  ENTR[n] <- results1$ENTR
  LAM[n] <- results1$LAM
  TT[n] <- results1$TT
  
  }
  
  else {
  
  PR[n] = NA
  DET[n] <- NA
  NRLINE[n] <- NA
  maxL[n] <- NA
  L[n] <- NA
  ENTR[n] <- NA
  LAM[n] <- NA
  TT[n] <- NA
  
  }
  
#increase n by 1 to index into the next value in the lists
  n = n + 1
  
}

# merge the list to a data frame
all_data_df_test <-  data.frame(Subject, study, trial, diagnosis, PR, DET, NRLINE, maxL, L, ENTR, LAM, TT, mean, sd, range, median)

#writedata frame to csv file
write.csv(all_data_df_test,file = "dfstudy1")

# end of LOOP
# removed from Karl's loop - not used in loop
  Subject[n] <-  substr(file, 14, 18)
  study[n] <-  substr(file, 7, 12)
  trial[n] <- sub("_", "", substr(file, 20, 21))
  diagnosis[n] <-  substr(file, 14, 14)
```

From class:
```{r}


#make 2 loops:
#loop 1 - collecting values 
#loop 2 - running the crqa on the original files 
results in a data frame  = data.frame(something)
return(results in a data frame)

dfd
	result = rcqa(sdfsf)
if length(result) > 1 
	telll it then what you want
else
tell it what you want (results = 0)

n = 1
For (1 in filelist) {
  x = read_csv(i)
  x = x$f0
  (crqa(x, x, delay = round(mean(DF$delay))))
  embed = ..
  Radius = ...

}

```


Sofie's loop:
```{r}
# make loop - f(x) / performance
# outcome variables 
filelist = list.files(path = "~/Desktop/Exp. Met. 3/Task_3/Pitch",pattern="*.txt")
setwd("~/Desktop/Exp. Met. 3/Task_3/Pitch")

Mean_pitch = NULL
SD_pitch = NULL
Participant = NULL
n = 1
Radius = 0

# loop 
For (i in filelist) { 
  x = read.delim(i)
  x = x$f0
    ID = str_extract(i, "S + \\d+")
  Participant[n] = str.extract (ID, "d\\D+")
  Mean_pitch[n] = round(mean(x, ra.rm = T), 2)
  SD_pitch[n] = SD(x, na.rm = T)
  V = optimizeParam(x, x, par, min.rec = 3.5, max.rec = 4.5)
  if (length(V) >1)  { 
     Radius[n] = V$radius
     Delay = V$delay
     Embed = V$emddim
  
  n = n+1

  }

df = data.frame(Participant, Mean_pitch, SD_pitch)
write.csv(df, file = "Pitchfile.csv")

# LOOP
install.packages("behappyR")
```

Celine:
looking at mean - SD - did still not make sense recurrence rate very high
radius 3 
piqr is also range (excluded the extremes)


recurrence rate tells us something about the length of different snippets "sequences" that are more likely to occur in c than s for example
l tells us somehting maybe the same?
Study Part Trial Gender Age PIQR

3. Make one model per acoustic feature and test whether you can observe significant difference due to Diagnosis. Tip: Which other fixed factors should you control for (that is, include in the model)? Which random ones?
- Bonus points: cross-validate the model and report the betas and standard errors from all rounds to get an idea of how robust the estimates are. 
3a. Is study a significant predictor in these models? What should you infer from this? Does study interact with diagnosis? What should you infer from this?

ass. 3:
lmer looking if diagnosis affects pitch 
pitch ~ 1 + D +  (1 streg study)

random effects with study meaning: participant in study 1 might be systematically different from study 2 (due to different equipment, experimenter, etc.)

having trial both in fixed and random effect: 
random effect + 1 + trial streg study =expecting pitch range to change systematically from trial to trial in a study (because you get bored in trial 10 - not because of diagnosis)

( 1 + D + trial streg P) the 2 types of participant 102 (= S102 and C102)
When you put D in the fixed effect you are saying to the model that difference in  diagnosis wary equally across each pair of c/s, but putting D also in the random effects means that the variance in each pair and therefore the difference between c/s across pairs might vary.  (the diagnosis varies across participant (P) pairs - pairs are different)
```{r}
MAKIN
all_data_df_test$Subject <- sub("^", "c", all_data_df_test$Subject)
all_data_df_test$Subject <- gsub("c", all_data_df_test$Subject)

PR_model = lmer(PR ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(PR_model)
DET_model = lmer(DET ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(DET_model) # significant 
NRLINE_model = lmer(NRLINE ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(NRLINE_model)
maxL_model = lmer(maxL ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(maxL_model)
L_model = lmer(L ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(L_model)
ENTR_model = lmer(ENTR ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(ENTR_model) # significant
LAM_model = lmer(LAM ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(LAM_model) # significant
TT_model = lmer(TT ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(TT_model) # significant

# alt + 1 = | (obelisk / vertical line)
# just to see the mean pitch:
model = lmer(mean ~ 1 + diagnosis + (1|study), data = all_data_df_test) 
summary(model)

#Does study have an effect on results?
study_PR_model = lm(PR ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_PR_model)
study_DET_model = lm(DET ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_DET_model) # significant 
study_NRLINE_model = lm(NRLINE ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_NRLINE_model) # significant
study_maxL_model = lm(maxL ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_maxL_model) # significant 
study_L_model = lm(L ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_L_model) # significant 
study_ENTR_model = lm(ENTR ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_ENTR_model) # significant
study_LAM_model = lm(LAM ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_LAM_model) # significant
study_TT_model = lm(TT ~ 1 + diagnosis + study, data = all_data_df_test) 
summary(study_TT_model)
"All acoutstic feature are significant across study between at least two of the studies, mostly the first two. 
```

4. Bonus Question: Compare effect size of diagnosis across the different measures. Which measure seems most sensitive?
- Tip: to compare across measures you need to put all of them on the same scale, that is, you need to "standardize" them (z-score)

5. Bonus question. In the Clinical Info file you have additional information about the participants. Which additional parameters (e.g. age, gender) should we control for? Report the effects.

6. Write a paragraph reporting methods and results

ANSWER:::::::::

1) Using the package stat.desc, we extracted the standard descriptors extracted of a random file (Study1D0S101T3_f0.txt). The descriptors can be seen in the following table. 
make table or just state mean = ...
mean = 106.29
std. dev. = 28.84
range = 153.75
median = 120.63
iqr = 
mean absoluted deviation = 
coefficient of variation = 

descriptors from the recurrence qualification analysis:
see Riccardos paper for explanations of what the different values are. 
RR (RR and PR is the same ) = 4.33 (raw amount of similarities between the ... )
DET = 98.75
NRLINE (the total number of lines int the recurrence plot) = 313
MaxL = 536
L = 39.24
ENTR = 3.34
LAM = 98.09
TT = 31.37

 Second you will have to turn the code into a function and loop through all the files (or even better use apply/sapply/lapply)
- Remember to extract the relevant information from the file names (Participant, Diagnosis, Trial, Study)
2) We made a loop where we looped through all the files in order to extract descriptors from the recurrence quantification analysis by means of the package crqa. The descriptors we obtained from the loop/recurrence quantification analysis are presented below. 

[Next assignment: can we use these measures to build a tool that diagnoses people from voice only?]

## N.B. Remember to save the acoustic features of voice in a separate file, so to be able to load them next time
